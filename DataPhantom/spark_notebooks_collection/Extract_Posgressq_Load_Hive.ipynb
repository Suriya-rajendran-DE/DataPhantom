{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15a12d19-6bfc-437d-87c1-5a1b302ca0e8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.31.178:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>HiveIntegration</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1b04917f550>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"HiveIntegration\") \\\n",
    "    .config(\"spark.sql.catalogImplementation\", \"hive\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"hdfs://localhost:9000/user/hive/warehouse\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8a3a5ba-3767-497c-8248-6e47034b8cee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Email: string (nullable = true)\n",
      " |-- Salary: string (nullable = true)\n",
      " |-- Joining_Date: string (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracted data from local into datafraem\n",
    "\n",
    "df = spark.read.csv(\"file:///D:/Apache_spark/datasets/emp_dept.csv\", header=True, inferSchema = True)\n",
    "\n",
    "df.printSchema()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cc2ee1-9b2c-401b-9a0b-c0113a5189bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded data in landing location\n",
    "\n",
    "df.write.format(\"csv\").option(\"header\", True).save(\"hdfs://localhost:9000/datasets/emp_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7737d61d-bcd7-4634-98b5-ed4e48d1c911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f301f77-fc98-4623-8b52-399246e31557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# created raw temp table and loaded data from landing location.\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "CREATE TABLE Raw_temp_table(\n",
    "    ID INT,\n",
    "    Name STRING,\n",
    "    Age STRING,\n",
    "    Email STRING,\n",
    "    Salary STRING,\n",
    "    Joining_Date STRING,\n",
    "    Status STRING,\n",
    "    Department STRING,\n",
    "    Experience INT,\n",
    "    LOCATION STRING\n",
    ")ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "STORED AS TEXTFILE\n",
    "LOCATION 'hdfs://localhost:9000/datasets/emp_data.csv'\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "LOAD DATA INPATH 'hdfs://localhost:9000/datasets/emp_data.csv' INTO TABLE Raw_temp_table;\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2994179c-756e-4769-86d1-afc2192b0b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+-------+\n",
      "|    col_name|data_type|comment|\n",
      "+------------+---------+-------+\n",
      "|          ID|      int|   NULL|\n",
      "|        Name|   string|   NULL|\n",
      "|         Age|   string|   NULL|\n",
      "|       Email|   string|   NULL|\n",
      "|      Salary|   string|   NULL|\n",
      "|Joining_Date|   string|   NULL|\n",
      "|      Status|   string|   NULL|\n",
      "|  Department|   string|   NULL|\n",
      "|  Experience|      int|   NULL|\n",
      "|    LOCATION|   string|   NULL|\n",
      "+------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"describe table Raw_temp_table\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a7a40d0-d90b-4878-99f2-8c557439516f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+-----------------+-----------+------------+--------+-----------+----------+-------------+\n",
      "| ID|   Name| Age|            Email|     Salary|Joining_Date|  Status| Department|Experience|     Location|\n",
      "+---+-------+----+-----------------+-----------+------------+--------+-----------+----------+-------------+\n",
      "|101|  Alice|  25|  alice@email.com|      50000|  2022-06-15|  Active|         HR|         3|     New York|\n",
      "|102|    Bob|NULL|       bob@domain|      60000|  2023-07-20|    NULL|    Finance|         5|       London|\n",
      "|103|  Alice|  25|  alice@email.com|      50000|  2022-06-15|  Active|         HR|         3|     New York|\n",
      "|104|Charlie|  28|charlie@email.com|     -45000|  2021-05-10|Inactive|Engineering|         7|       Berlin|\n",
      "|105|  Diana|NULL|  diana@email.com|       NULL|  2019-03-25|  Active|  Marketing|      NULL|        Paris|\n",
      "|106|   NULL|  30|    invalid-email|      70000|  2024-09-18|  Active|      Sales|         4|        Tokyo|\n",
      "|107|  Eddie|  22|  eddie@email.com|      40000|        NULL|  Active|         IT|         1|San Francisco|\n",
      "|108|  Fiona|  26|  fiona@email.com|      55000|  2023-11-05|    NULL|    Finance|         6|       Sydney|\n",
      "|109|   Gary|  27|             NULL|      75000|  2020-02-29|  Active|         HR|         2|       Mumbai|\n",
      "|110|  Helen|NULL|  helen@email.com|      45000|  2018-06-07|Inactive|  Marketing|         8|        Dubai|\n",
      "|111|   John|NULL|   john@email.com|      80000|  2021-11-10|  Active|         IT|         3|     New York|\n",
      "|112|   Kate|  29|   invalid@domain|      48000|  2022-04-18|  Active|Engineering|         5|       London|\n",
      "|113|  Louis|  26|      louis@email|      70000|  2020.03.30|Inactive|         HR|         4|       Berlin|\n",
      "|114|   Mark|  35|   mark@email.com|text_salary|  2018-12-15|  Active|      Sales|        10|        Paris|\n",
      "|115|   Nina|  28|   nina@email.com|      55000|    06/15/22|  Active|  Marketing|         6|        Tokyo|\n",
      "+---+-------+----+-----------------+-----------+------------+--------+-----------+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "055ceeff-815c-4fc0-a396-31b1d4bf17d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting raw table data into df from trasformation\n",
    "\n",
    "df = spark.sql(\"SELECT * FROM Raw_temp_table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bef2729-5f91-4cf5-903b-ef2a65214920",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----+-----------------+-----------+------------+--------+-----------+----------+-------------+\n",
      "|  ID|   Name| Age|            Email|     Salary|Joining_Date|  Status| Department|Experience|     LOCATION|\n",
      "+----+-------+----+-----------------+-----------+------------+--------+-----------+----------+-------------+\n",
      "|NULL|   Name| Age|            Email|     Salary|Joining_Date|  Status| Department|      NULL|     Location|\n",
      "| 101|  Alice|  25|  alice@email.com|      50000|  2022-06-15|  Active|         HR|         3|     New York|\n",
      "| 102|    Bob|    |       bob@domain|      60000|  2023-07-20|        |    Finance|         5|       London|\n",
      "| 103|  Alice|  25|  alice@email.com|      50000|  2022-06-15|  Active|         HR|         3|     New York|\n",
      "| 104|Charlie|  28|charlie@email.com|     -45000|  2021-05-10|Inactive|Engineering|         7|       Berlin|\n",
      "| 105|  Diana|NULL|  diana@email.com|           |  2019-03-25|  Active|  Marketing|      NULL|        Paris|\n",
      "| 106|   NULL|  30|    invalid-email|      70000|  2024-09-18|  Active|      Sales|         4|        Tokyo|\n",
      "| 107|  Eddie|  22|  eddie@email.com|      40000|            |  Active|         IT|         1|San Francisco|\n",
      "| 108|  Fiona|  26|  fiona@email.com|      55000|  2023-11-05|    NULL|    Finance|         6|       Sydney|\n",
      "| 109|   Gary|  27|                 |      75000|  2020-02-29|  Active|         HR|         2|       Mumbai|\n",
      "| 110|  Helen|NULL|  helen@email.com|      45000|  2018-06-07|Inactive|  Marketing|         8|        Dubai|\n",
      "| 111|   John|    |   john@email.com|      80000|  2021-11-10|  Active|         IT|         3|     New York|\n",
      "| 112|   Kate|  29|   invalid@domain|      48000|  2022-04-18|  Active|Engineering|         5|       London|\n",
      "| 113|  Louis|  26|      louis@email|      70000|  2020.03.30|Inactive|         HR|         4|       Berlin|\n",
      "| 114|   Mark|  35|   mark@email.com|text_salary|  2018-12-15|  Active|      Sales|        10|        Paris|\n",
      "| 115|   Nina|  28|   nina@email.com|      55000|    06/15/22|  Active|  Marketing|         6|        Tokyo|\n",
      "+----+-------+----+-----------------+-----------+------------+--------+-----------+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4c9f2c1-96f9-494e-b18c-e1ccf5a5c851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+---+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "|  ID|   Name|Age|            Email|Salary|Joining_Date|  Status| Department|Experience|LOCATION|\n",
      "+----+-------+---+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "|NULL|   Name|Age|            Email|Salary|Joining_Date|  Status| Department|      NULL|Location|\n",
      "| 102|    Bob|   |       bob@domain| 60000|  2023-07-20|        |    Finance|         5|  London|\n",
      "| 104|Charlie| 28|charlie@email.com|-45000|  2021-05-10|Inactive|Engineering|         7|  Berlin|\n",
      "| 106|   NULL| 30|    invalid-email| 70000|  2024-09-18|  Active|      Sales|         4|   Tokyo|\n",
      "| 109|   Gary| 27|                 | 75000|  2020-02-29|  Active|         HR|         2|  Mumbai|\n",
      "| 112|   Kate| 29|   invalid@domain| 48000|  2022-04-18|  Active|Engineering|         5|  London|\n",
      "| 113|  Louis| 26|      louis@email| 70000|  2020.03.30|Inactive|         HR|         4|  Berlin|\n",
      "+----+-------+---+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Define bad record conditions\n",
    "bad_records_df = df.filter(\n",
    "    (col(\"Age\").isNull()) |  # Check for missing Age\n",
    "    (~col(\"Email\").rlike(\"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\\\.[a-zA-Z0-9-.]+$\")) |  # Invalid Email\n",
    "    (col(\"Salary\").isNull()) | (col(\"Salary\") <= 0)  # Salary must be positive\n",
    ")\n",
    "\n",
    "bad_records_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84cc84a0-fd3f-4022-811f-cc16e92fdb5a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+---+-----------------+------+------------+--------+-----------+----------+--------+----------+\n",
      "|  ID|   Name|Age|            Email|Salary|Joining_Date|  Status| Department|Experience|LOCATION|bad_record|\n",
      "+----+-------+---+-----------------+------+------------+--------+-----------+----------+--------+----------+\n",
      "|NULL|   Name|Age|            Email|Salary|Joining_Date|  Status| Department|      NULL|Location|   Corrupt|\n",
      "| 102|    Bob|   |       bob@domain| 60000|  2023-07-20|        |    Finance|         5|  London|   Corrupt|\n",
      "| 104|Charlie| 28|charlie@email.com|-45000|  2021-05-10|Inactive|Engineering|         7|  Berlin|   Corrupt|\n",
      "| 106|   NULL| 30|    invalid-email| 70000|  2024-09-18|  Active|      Sales|         4|   Tokyo|   Corrupt|\n",
      "| 109|   Gary| 27|                 | 75000|  2020-02-29|  Active|         HR|         2|  Mumbai|   Corrupt|\n",
      "| 112|   Kate| 29|   invalid@domain| 48000|  2022-04-18|  Active|Engineering|         5|  London|   Corrupt|\n",
      "| 113|  Louis| 26|      louis@email| 70000|  2020.03.30|Inactive|         HR|         4|  Berlin|   Corrupt|\n",
      "+----+-------+---+-----------------+------+------------+--------+-----------+----------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "df_p = bad_records_df .withColumn(\"bad_record\", \n",
    "    when((col(\"Age\").isNull()) | (~col(\"Email\").rlike(\"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\\\.[a-zA-Z0-9-.]+$\")) |\n",
    "         (col(\"Salary\").isNull()) | (col(\"Salary\") <= 0), \"Corrupt\").otherwise(None)\n",
    ")\n",
    "\n",
    "df_p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26d4f20e-9fe2-4ef1-a755-bd387034a1f4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+-----------------+------+------------+--------+-----------+----------+--------+----------+\n",
      "| ID|   Name|Age|            Email|Salary|Joining_Date|  Status| Department|Experience|LOCATION|bad_record|\n",
      "+---+-------+---+-----------------+------+------------+--------+-----------+----------+--------+----------+\n",
      "|102|   Name|Age|            Email|Salary|Joining_Date|  Status| Department|         1|Location|   Corrupt|\n",
      "|102|    Bob|   |       bob@domain| 60000|  2023-07-20|        |    Finance|         5|  London|   Corrupt|\n",
      "|104|Charlie| 28|charlie@email.com|-45000|  2021-05-10|Inactive|Engineering|         7|  Berlin|   Corrupt|\n",
      "|106|   NULL| 30|    invalid-email| 70000|  2024-09-18|  Active|      Sales|         4|   Tokyo|   Corrupt|\n",
      "|109|   Gary| 27|                 | 75000|  2020-02-29|  Active|         HR|         2|  Mumbai|   Corrupt|\n",
      "|112|   Kate| 29|   invalid@domain| 48000|  2022-04-18|  Active|Engineering|         5|  London|   Corrupt|\n",
      "|113|  Louis| 26|      louis@email| 70000|  2020.03.30|Inactive|         HR|         4|  Berlin|   Corrupt|\n",
      "+---+-------+---+-----------------+------+------------+--------+-----------+----------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hadling Null records with default records\n",
    "\n",
    "df_p = df_p.na.fill({\n",
    "    \"ID\": 102,  # Default id if missing\n",
    "    \"Age\": 25,  # Default age if missing\n",
    "    \"Salary\": 30000,  # Assign minimum salary\n",
    "    \"Status\": \"Active\", # Assign missing user are active\n",
    "    \"Experience\": 1,\n",
    "    \"Joining_Date\": \"2021-05-10\",\n",
    "    \"LOCATION\": \"India\"\n",
    "})\n",
    "\n",
    "df_p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5fbb3ca4-9659-4322-9d3b-e8edf6551eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+-----------------+------+------------+--------+-----------+----------+--------+----------+\n",
      "| ID|   Name|Age|            Email|Salary|Joining_Date|  Status| Department|Experience|LOCATION|bad_record|\n",
      "+---+-------+---+-----------------+------+------------+--------+-----------+----------+--------+----------+\n",
      "|102|   Name|Age|unknown@email.com|Salary|Joining_Date|  Status| Department|         1|Location|   Corrupt|\n",
      "|102|    Bob|   |unknown@email.com| 60000|  2023-07-20|        |    Finance|         5|  London|   Corrupt|\n",
      "|104|Charlie| 28|charlie@email.com| 30000|  2021-05-10|Inactive|Engineering|         7|  Berlin|   Corrupt|\n",
      "|106|   NULL| 30|unknown@email.com| 70000|  2024-09-18|  Active|      Sales|         4|   Tokyo|   Corrupt|\n",
      "|109|   Gary| 27|unknown@email.com| 75000|  2020-02-29|  Active|         HR|         2|  Mumbai|   Corrupt|\n",
      "|112|   Kate| 29|unknown@email.com| 48000|  2022-04-18|  Active|Engineering|         5|  London|   Corrupt|\n",
      "|113|  Louis| 26|unknown@email.com| 70000|  2020.03.30|Inactive|         HR|         4|  Berlin|   Corrupt|\n",
      "+---+-------+---+-----------------+------+------------+--------+-----------+----------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hadling the bad records into good records\n",
    "\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "df_p = df_p.withColumn(\"Email\", \n",
    "    when(~col(\"Email\").rlike(\"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\\\.[a-zA-Z0-9-.]+$\"), \"unknown@email.com\")\n",
    "    .otherwise(col(\"Email\"))\n",
    ")\n",
    "\n",
    "df_p = df_p.withColumn(\"Salary\", when(col(\"Salary\") < 0, 30000).otherwise(col(\"Salary\")))\n",
    "\n",
    "df_p = df_p.withColumn(\"Experience\", when(col(\"Experience\") < 0, 1).otherwise(col(\"Experience\")))\n",
    "\n",
    "df_p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "073f8519-3c8b-495b-ac1b-74bef925fba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+-----------------+------+------------+--------+-----------+----------+--------+----------+\n",
      "| ID|   Name|Age|            Email|Salary|Joining_Date|  Status| Department|Experience|LOCATION|bad_record|\n",
      "+---+-------+---+-----------------+------+------------+--------+-----------+----------+--------+----------+\n",
      "|102|   Name|Age|unknown@email.com|Salary|Joining_Date|  Status| Department|         1|Location|   Corrupt|\n",
      "|102|    Bob| 25|unknown@email.com| 60000|  2023-07-20|  Active|    Finance|         5|  London|   Corrupt|\n",
      "|104|Charlie| 28|charlie@email.com| 30000|  2021-05-10|Inactive|Engineering|         7|  Berlin|   Corrupt|\n",
      "|106|   NULL| 30|unknown@email.com| 70000|  2024-09-18|  Active|      Sales|         4|   Tokyo|   Corrupt|\n",
      "|109|   Gary| 27|unknown@email.com| 75000|  2020-02-29|  Active|         HR|         2|  Mumbai|   Corrupt|\n",
      "|112|   Kate| 29|unknown@email.com| 48000|  2022-04-18|  Active|Engineering|         5|  London|   Corrupt|\n",
      "|113|  Louis| 26|unknown@email.com| 70000|  2020.03.30|Inactive|         HR|         4|  Berlin|   Corrupt|\n",
      "+---+-------+---+-----------------+------+------------+--------+-----------+----------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, col, trim\n",
    "\n",
    "df_p = df_p.withColumn(\"Name\", when(col(\"Name\").isNull() | (trim(col(\"Name\")) == \"\"), \"Unknown\").otherwise(col(\"Name\")))\n",
    "df_p = df_p.withColumn(\"Age\", when(col(\"Age\").isNull() | (trim(col(\"Age\")) == \"\"), 25).otherwise(col(\"Age\")))\n",
    "df_p = df_p.withColumn(\"Salary\", when(col(\"Salary\").isNull() | (trim(col(\"Name\")) == \"\"), 30000).otherwise(col(\"Salary\")))\n",
    "df_p = df_p.withColumn(\"Status\", when(col(\"Status\").isNull() | (trim(col(\"Status\")) == \"\"), \"Active\").otherwise(col(\"Status\")))\n",
    "df_p = df_p.withColumn(\"Department\", when(col(\"Department\").isNull() | (trim(col(\"Department\")) == \"\"), \"Engineering\").otherwise(col(\"Department\")))\n",
    "\n",
    "df_p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "481cf87c-6af7-4d80-91c0-be8568dbc483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+-----------------+------+------------+--------+-----------+----------+--------+----------+\n",
      "| ID|   Name|Age|            Email|Salary|Joining_Date|  Status| Department|Experience|LOCATION|bad_record|\n",
      "+---+-------+---+-----------------+------+------------+--------+-----------+----------+--------+----------+\n",
      "|102|   Name|Age|unknown@email.com| 30000|        NULL|  Status| Department|         1|Location|   Corrupt|\n",
      "|102|    Bob| 25|unknown@email.com| 60000|  2023-07-20|  Active|    Finance|         5|  London|   Corrupt|\n",
      "|104|Charlie| 28|charlie@email.com| 30000|  2021-05-10|Inactive|Engineering|         7|  Berlin|   Corrupt|\n",
      "|106|   NULL| 30|unknown@email.com| 70000|  2024-09-18|  Active|      Sales|         4|   Tokyo|   Corrupt|\n",
      "|109|   Gary| 27|unknown@email.com| 75000|  2020-02-29|  Active|         HR|         2|  Mumbai|   Corrupt|\n",
      "|112|   Kate| 29|unknown@email.com| 48000|  2022-04-18|  Active|Engineering|         5|  London|   Corrupt|\n",
      "|113|  Louis| 26|unknown@email.com| 70000|        NULL|Inactive|         HR|         4|  Berlin|   Corrupt|\n",
      "+---+-------+---+-----------------+------+------------+--------+-----------+----------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date, when, col\n",
    "\n",
    "df_p = df_p.withColumn(\"Joining_Date\", to_date(col(\"Joining_Date\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "df_p = df_p.withColumn(\"Salary\", \n",
    "    when(col(\"Salary\").isNull() | (~col(\"Salary\").rlike(\"^[0-9]+$\")) | (col(\"Salary\") <= 0), 30000)\n",
    "    .otherwise(col(\"Salary\").cast(\"int\"))\n",
    ")\n",
    "\n",
    "df_p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f1c0273-6f57-47e2-a06b-1de1588bfdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+-----------------+------+------------+--------+-----------+----------+--------+----------+\n",
      "| ID|   Name|Age|            Email|Salary|Joining_Date|  Status| Department|Experience|LOCATION|bad_record|\n",
      "+---+-------+---+-----------------+------+------------+--------+-----------+----------+--------+----------+\n",
      "|102|   Name|Age|unknown@email.com| 30000|        NULL|  Status| Department|         1|Location|   Corrupt|\n",
      "|102|    Bob| 25|unknown@email.com| 60000|  2023-07-20|  Active|    Finance|         5|  London|   Corrupt|\n",
      "|104|Charlie| 28|charlie@email.com| 30000|  2021-05-10|Inactive|Engineering|         7|  Berlin|   Corrupt|\n",
      "|106|   NULL| 30|unknown@email.com| 70000|  2024-09-18|  Active|      Sales|         4|   Tokyo|   Corrupt|\n",
      "|109|   Gary| 27|unknown@email.com| 75000|  2020-02-29|  Active|         HR|         2|  Mumbai|   Corrupt|\n",
      "|112|   Kate| 29|unknown@email.com| 48000|  2022-04-18|  Active|Engineering|         5|  London|   Corrupt|\n",
      "|113|  Louis| 26|unknown@email.com| 70000|        NULL|Inactive|         HR|         4|  Berlin|   Corrupt|\n",
      "+---+-------+---+-----------------+------+------------+--------+-----------+----------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_p.na.fill({\n",
    "    \"Joining_Date\": \"2024-07-08\"\n",
    "})\n",
    "\n",
    "df_p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3703415d-241b-4d55-9e19-d71c0665cde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "df_p = df_p.withColumn(\"Joining_Date\", \n",
    "    when(col(\"Joining_Date\").isNull() | (col(\"Joining_Date\") == \"\"), \"2024-07-08\")\n",
    "    .otherwise(col(\"Joining_Date\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4483139b-06a4-459e-a94f-b6b28b25a7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+-----------------+------+------------+--------+-----------+----------+--------+----------+\n",
      "| ID|   Name|Age|            Email|Salary|Joining_Date|  Status| Department|Experience|LOCATION|bad_record|\n",
      "+---+-------+---+-----------------+------+------------+--------+-----------+----------+--------+----------+\n",
      "|102|   Name|Age|unknown@email.com| 30000|  2024-07-08|  Status| Department|         1|Location|   Corrupt|\n",
      "|102|    Bob| 25|unknown@email.com| 60000|  2023-07-20|  Active|    Finance|         5|  London|   Corrupt|\n",
      "|104|Charlie| 28|charlie@email.com| 30000|  2021-05-10|Inactive|Engineering|         7|  Berlin|   Corrupt|\n",
      "|106|   NULL| 30|unknown@email.com| 70000|  2024-09-18|  Active|      Sales|         4|   Tokyo|   Corrupt|\n",
      "|109|   Gary| 27|unknown@email.com| 75000|  2020-02-29|  Active|         HR|         2|  Mumbai|   Corrupt|\n",
      "|112|   Kate| 29|unknown@email.com| 48000|  2022-04-18|  Active|Engineering|         5|  London|   Corrupt|\n",
      "|113|  Louis| 26|unknown@email.com| 70000|  2024-07-08|Inactive|         HR|         4|  Berlin|   Corrupt|\n",
      "+---+-------+---+-----------------+------+------------+--------+-----------+----------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b1e66423-bf70-4f99-b60c-21373cf49b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = df_p.drop(\"bad_record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0f91838b-23fc-4aba-a2cb-11177dbd94a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "| ID|   Name|Age|            Email|Salary|Joining_Date|  Status| Department|Experience|LOCATION|\n",
      "+---+-------+---+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "|102|   Name|Age|unknown@email.com| 30000|  2024-07-08|  Status| Department|         1|Location|\n",
      "|102|    Bob| 25|unknown@email.com| 60000|  2023-07-20|  Active|    Finance|         5|  London|\n",
      "|104|Charlie| 28|charlie@email.com| 30000|  2021-05-10|Inactive|Engineering|         7|  Berlin|\n",
      "|106|   NULL| 30|unknown@email.com| 70000|  2024-09-18|  Active|      Sales|         4|   Tokyo|\n",
      "|109|   Gary| 27|unknown@email.com| 75000|  2020-02-29|  Active|         HR|         2|  Mumbai|\n",
      "|112|   Kate| 29|unknown@email.com| 48000|  2022-04-18|  Active|Engineering|         5|  London|\n",
      "|113|  Louis| 26|unknown@email.com| 70000|  2024-07-08|Inactive|         HR|         4|  Berlin|\n",
      "+---+-------+---+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8964b4dd-3b0f-4b36-a1dd-5c81131d6da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "| id|   name|age|            email|salary|joining_date|  status| department|experience|location|\n",
      "+---+-------+---+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "|102|   Name|Age|unknown@email.com| 30000|  2024-07-08|  Status| Department|         1|Location|\n",
      "|102|    Bob| 25|unknown@email.com| 60000|  2023-07-20|  Active|    Finance|         5|  London|\n",
      "|104|Charlie| 28|charlie@email.com| 30000|  2021-05-10|Inactive|Engineering|         7|  Berlin|\n",
      "|106|   NULL| 30|unknown@email.com| 70000|  2024-09-18|  Active|      Sales|         4|   Tokyo|\n",
      "|109|   Gary| 27|unknown@email.com| 75000|  2020-02-29|  Active|         HR|         2|  Mumbai|\n",
      "|112|   Kate| 29|unknown@email.com| 48000|  2022-04-18|  Active|Engineering|         5|  London|\n",
      "|113|  Louis| 26|unknown@email.com| 70000|  2024-07-08|Inactive|         HR|         4|  Berlin|\n",
      "+---+-------+---+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transformed = df_p.toDF(\"id\", \"name\", \"age\", \"email\", \"salary\", \"joining_date\", \"status\", \"department\", \"experience\", \"location\")\n",
    "\n",
    "df_transformed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aeda6295-751e-489f-a31c-ef26cf1e74fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+---------------+------+------------+--------+-----------+----------+-------------+\n",
      "| ID| Name| Age|          Email|Salary|Joining_Date|  Status| Department|Experience|     LOCATION|\n",
      "+---+-----+----+---------------+------+------------+--------+-----------+----------+-------------+\n",
      "|101|Alice|  25|alice@email.com| 50000|  2022-06-15|  Active|         HR|         3|     New York|\n",
      "|102|  Bob|    |     bob@domain| 60000|  2023-07-20|        |    Finance|         5|       London|\n",
      "|103|Alice|  25|alice@email.com| 50000|  2022-06-15|  Active|         HR|         3|     New York|\n",
      "|106| NULL|  30|  invalid-email| 70000|  2024-09-18|  Active|      Sales|         4|        Tokyo|\n",
      "|107|Eddie|  22|eddie@email.com| 40000|            |  Active|         IT|         1|San Francisco|\n",
      "|108|Fiona|  26|fiona@email.com| 55000|  2023-11-05|    NULL|    Finance|         6|       Sydney|\n",
      "|109| Gary|  27|               | 75000|  2020-02-29|  Active|         HR|         2|       Mumbai|\n",
      "|110|Helen|NULL|helen@email.com| 45000|  2018-06-07|Inactive|  Marketing|         8|        Dubai|\n",
      "|111| John|    | john@email.com| 80000|  2021-11-10|  Active|         IT|         3|     New York|\n",
      "|112| Kate|  29| invalid@domain| 48000|  2022-04-18|  Active|Engineering|         5|       London|\n",
      "|113|Louis|  26|    louis@email| 70000|  2020.03.30|Inactive|         HR|         4|       Berlin|\n",
      "|115| Nina|  28| nina@email.com| 55000|    06/15/22|  Active|  Marketing|         6|        Tokyo|\n",
      "+---+-----+----+---------------+------+------------+--------+-----------+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_original_clean = df.filter(\n",
    "    col(\"Salary\").isNotNull() & (~col(\"Salary\").rlike(\"^[^0-9]+$\")) & (col(\"Salary\") > 0) &\n",
    "    col(\"Joining_Date\").isNotNull()\n",
    ")\n",
    "\n",
    "df_original_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a18df39d-12e0-4460-a991-bb491a731b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+---------------+------+------------+--------+----------+----------+--------+\n",
      "| ID| Name| Age|          Email|Salary|Joining_Date|  Status|Department|Experience|LOCATION|\n",
      "+---+-----+----+---------------+------+------------+--------+----------+----------+--------+\n",
      "|101|Alice|  25|alice@email.com| 50000|  2022-06-15|  Active|        HR|         3|New York|\n",
      "|103|Alice|  25|alice@email.com| 50000|  2022-06-15|  Active|        HR|         3|New York|\n",
      "|108|Fiona|  26|fiona@email.com| 55000|  2023-11-05|    NULL|   Finance|         6|  Sydney|\n",
      "|110|Helen|NULL|helen@email.com| 45000|  2018-06-07|Inactive| Marketing|         8|   Dubai|\n",
      "|111| John|    | john@email.com| 80000|  2021-11-10|  Active|        IT|         3|New York|\n",
      "|115| Nina|  28| nina@email.com| 55000|    06/15/22|  Active| Marketing|         6|   Tokyo|\n",
      "+---+-----+----+---------------+------+------------+--------+----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_good_records = df.filter(\n",
    "    (col(\"Salary\").isNotNull()) & (col(\"Salary\").rlike(\"^[0-9]+$\")) & (col(\"Salary\") > 0) & \n",
    "    (col(\"Joining_Date\").isNotNull()) & (col(\"Joining_Date\") != \"\") & \n",
    "    (col(\"Email\").rlike(\"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\\\.[a-zA-Z0-9-.]+$\"))\n",
    ")\n",
    "\n",
    "df_good_records.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f20d076c-e8f0-48ba-8c5c-de787e25a584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+---------------+------+------------+--------+----------+----------+--------+----+----+----+-----+------+------------+------+----------+----------+--------+\n",
      "| ID| Name| Age|          Email|Salary|Joining_Date|  Status|Department|Experience|LOCATION|  id|name| age|email|salary|joining_date|status|department|experience|location|\n",
      "+---+-----+----+---------------+------+------------+--------+----------+----------+--------+----+----+----+-----+------+------------+------+----------+----------+--------+\n",
      "|101|Alice|  25|alice@email.com| 50000|  2022-06-15|  Active|        HR|         3|New York|NULL|NULL|NULL| NULL|  NULL|        NULL|  NULL|      NULL|      NULL|    NULL|\n",
      "|103|Alice|  25|alice@email.com| 50000|  2022-06-15|  Active|        HR|         3|New York|NULL|NULL|NULL| NULL|  NULL|        NULL|  NULL|      NULL|      NULL|    NULL|\n",
      "|108|Fiona|  26|fiona@email.com| 55000|  2023-11-05|    NULL|   Finance|         6|  Sydney|NULL|NULL|NULL| NULL|  NULL|        NULL|  NULL|      NULL|      NULL|    NULL|\n",
      "|110|Helen|NULL|helen@email.com| 45000|  2018-06-07|Inactive| Marketing|         8|   Dubai|NULL|NULL|NULL| NULL|  NULL|        NULL|  NULL|      NULL|      NULL|    NULL|\n",
      "|111| John|    | john@email.com| 80000|  2021-11-10|  Active|        IT|         3|New York|NULL|NULL|NULL| NULL|  NULL|        NULL|  NULL|      NULL|      NULL|    NULL|\n",
      "|115| Nina|  28| nina@email.com| 55000|    06/15/22|  Active| Marketing|         6|   Tokyo|NULL|NULL|NULL| NULL|  NULL|        NULL|  NULL|      NULL|      NULL|    NULL|\n",
      "+---+-----+----+---------------+------+------------+--------+----------+----------+--------+----+----+----+-----+------+------------+------+----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = df_good_records.join(df_transformed, df[\"ID\"] == df_transformed[\"id\"], how=\"left\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0d351614-c0c4-4ffe-b6e2-71d202dfe14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "| ID|   Name| Age|            Email|Salary|Joining_Date|  Status| Department|Experience|LOCATION|\n",
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "|101|  Alice|  25|  alice@email.com| 50000|  2022-06-15|  Active|         HR|         3|New York|\n",
      "|103|  Alice|  25|  alice@email.com| 50000|  2022-06-15|  Active|         HR|         3|New York|\n",
      "|108|  Fiona|  26|  fiona@email.com| 55000|  2023-11-05|    NULL|    Finance|         6|  Sydney|\n",
      "|110|  Helen|NULL|  helen@email.com| 45000|  2018-06-07|Inactive|  Marketing|         8|   Dubai|\n",
      "|111|   John|    |   john@email.com| 80000|  2021-11-10|  Active|         IT|         3|New York|\n",
      "|115|   Nina|  28|   nina@email.com| 55000|    06/15/22|  Active|  Marketing|         6|   Tokyo|\n",
      "|102|   Name| Age|unknown@email.com| 30000|  2024-07-08|  Status| Department|         1|Location|\n",
      "|102|    Bob|  25|unknown@email.com| 60000|  2023-07-20|  Active|    Finance|         5|  London|\n",
      "|104|Charlie|  28|charlie@email.com| 30000|  2021-05-10|Inactive|Engineering|         7|  Berlin|\n",
      "|106|   NULL|  30|unknown@email.com| 70000|  2024-09-18|  Active|      Sales|         4|   Tokyo|\n",
      "|109|   Gary|  27|unknown@email.com| 75000|  2020-02-29|  Active|         HR|         2|  Mumbai|\n",
      "|112|   Kate|  29|unknown@email.com| 48000|  2022-04-18|  Active|Engineering|         5|  London|\n",
      "|113|  Louis|  26|unknown@email.com| 70000|  2024-07-08|Inactive|         HR|         4|  Berlin|\n",
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_r = df_good_records.union(df_transformed)\n",
    "df_r.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7f4914cf-1dab-4de9-a998-ed8bc06051c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "72e73371-1b53-4d08-b16d-2ea17c410cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "| ID|   Name| Age|            Email|Salary|Joining_Date|  Status| Department|Experience|LOCATION|\n",
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "|101|  Alice|  25|  alice@email.com| 50000|  2022-06-15|  Active|         HR|         3|New York|\n",
      "|103|  Alice|  25|  alice@email.com| 50000|  2022-06-15|  Active|         HR|         3|New York|\n",
      "|108|  Fiona|  26|  fiona@email.com| 55000|  2023-11-05|    NULL|    Finance|         6|  Sydney|\n",
      "|110|  Helen|NULL|  helen@email.com| 45000|  2018-06-07|Inactive|  Marketing|         8|   Dubai|\n",
      "|111|   John|  25|   john@email.com| 80000|  2021-11-10|  Active|         IT|         3|New York|\n",
      "|115|   Nina|  28|   nina@email.com| 55000|  2024-07-08|  Active|  Marketing|         6|   Tokyo|\n",
      "|102|   Name| Age|unknown@email.com| 30000|  2024-07-08|  Status| Department|         1|Location|\n",
      "|102|    Bob|  25|unknown@email.com| 60000|  2023-07-20|  Active|    Finance|         5|  London|\n",
      "|104|Charlie|  28|charlie@email.com| 30000|  2021-05-10|Inactive|Engineering|         7|  Berlin|\n",
      "|106|   NULL|  30|unknown@email.com| 70000|  2024-09-18|  Active|      Sales|         4|   Tokyo|\n",
      "|109|   Gary|  27|unknown@email.com| 75000|  2020-02-29|  Active|         HR|         2|  Mumbai|\n",
      "|112|   Kate|  29|unknown@email.com| 48000|  2022-04-18|  Active|Engineering|         5|  London|\n",
      "|113|  Louis|  26|unknown@email.com| 70000|  2024-07-08|Inactive|         HR|         4|  Berlin|\n",
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, col, to_date, trim\n",
    "\n",
    "df_r = df_r.withColumn(\"Joining_Date\", to_date(col(\"Joining_Date\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "df_r = df_r.withColumn(\"Joining_Date\", when(col(\"Joining_Date\").isNull() | (col(\"Joining_Date\") == \"\"), \"2024-07-08\").otherwise(col(\"Joining_Date\")))\n",
    "\n",
    "df_r = df_r.withColumn(\"Salary\", when(col(\"Salary\").isNull() | (~col(\"Salary\").rlike(\"^[0-9]+$\")) | (col(\"Salary\") <= 0) | (trim(col(\"Salary\")) == \"\"), 30000).otherwise(col(\"Salary\").cast(\"int\")))\n",
    "\n",
    "df_r = df_r.withColumn(\"Name\", when(col(\"Name\").isNull() | (trim(col(\"Name\")) == \"\"), \"Unknown\").otherwise(col(\"Name\")))\n",
    "df_r= df_r.withColumn(\"Age\", when(col(\"Age\").isNull() | (trim(col(\"Age\")) == \"\"), 25).otherwise(col(\"Age\")))\n",
    "\n",
    "df_r = df_r.withColumn(\"Status\", when(col(\"Status\").isNull() | (trim(col(\"Status\")) == \"\"), \"Active\").otherwise(col(\"Status\")))\n",
    "df_r = df_r.withColumn(\"Department\", when(col(\"Department\").isNull() | (trim(col(\"Department\")) == \"\"), \"Engineering\").otherwise(col(\"Department\")))\n",
    "df_r = df_r.withColumn(\"Email\", when(~col(\"Email\").rlike(\"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\\\.[a-zA-Z0-9-.]+$\"), \"unknown@email.com\").otherwise(col(\"Email\")))\n",
    "\n",
    "df_r = df_r.withColumn(\"Experience\", when(col(\"Experience\") < 0, 1).otherwise(col(\"Experience\")))\n",
    "\n",
    "df_r.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "539298bd-2580-46ec-8fa3-5fe1907e0c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "| ID|   Name| Age|            Email|Salary|Joining_Date|  Status| Department|Experience|LOCATION|\n",
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "|101|  Alice|  25|  alice@email.com| 50000|  2022-06-15|  Active|         HR|         3|New York|\n",
      "|103|  Alice|  25|  alice@email.com| 50000|  2022-06-15|  Active|         HR|         3|New York|\n",
      "|108|  Fiona|  26|  fiona@email.com| 55000|  2023-11-05|    NULL|    Finance|         6|  Sydney|\n",
      "|110|  Helen|NULL|  helen@email.com| 45000|  2018-06-07|Inactive|  Marketing|         8|   Dubai|\n",
      "|111|   John|  25|   john@email.com| 80000|  2021-11-10|  Active|         IT|         3|New York|\n",
      "|115|   Nina|  28|   nina@email.com| 55000|  2024-07-08|  Active|  Marketing|         6|   Tokyo|\n",
      "|102|   Name| Age|unknown@email.com| 30000|  2024-07-08|  Status| Department|         1|Location|\n",
      "|102|    Bob|  25|unknown@email.com| 60000|  2023-07-20|  Active|    Finance|         5|  London|\n",
      "|104|Charlie|  28|charlie@email.com| 30000|  2021-05-10|Inactive|Engineering|         7|  Berlin|\n",
      "|106|   NULL|  30|unknown@email.com| 70000|  2024-09-18|  Active|      Sales|         4|   Tokyo|\n",
      "|109|   Gary|  27|unknown@email.com| 75000|  2020-02-29|  Active|         HR|         2|  Mumbai|\n",
      "|112|   Kate|  29|unknown@email.com| 48000|  2022-04-18|  Active|Engineering|         5|  London|\n",
      "|113|  Louis|  26|unknown@email.com| 70000|  2024-07-08|Inactive|         HR|         4|  Berlin|\n",
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_r = df_r.withColumn(\"Status\", when(col(\"Status\").isNull() | (trim(col(\"Status\")) == \"\"), \"Active\").otherwise(col(\"Status\"))) \\\n",
    "           .withColumn(\"Age\", when(col(\"Age\").isNull() | (trim(col(\"Age\")) == \"\"), 25).otherwise(col(\"Age\")))\n",
    "\n",
    "df_r.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b968de29-a03a-42e1-8769-97b4fd18d79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "| ID|   Name| Age|            Email|Salary|Joining_Date|  Status| Department|Experience|LOCATION|\n",
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "|101|  Alice|  25|  alice@email.com| 50000|  2022-06-15|  Active|         HR|         3|New York|\n",
      "|103|  Alice|  25|  alice@email.com| 50000|  2022-06-15|  Active|         HR|         3|New York|\n",
      "|108|  Fiona|  26|  fiona@email.com| 55000|  2023-11-05|    NULL|    Finance|         6|  Sydney|\n",
      "|110|  Helen|NULL|  helen@email.com| 45000|  2018-06-07|Inactive|  Marketing|         8|   Dubai|\n",
      "|111|   John|  25|   john@email.com| 80000|  2021-11-10|  Active|         IT|         3|New York|\n",
      "|115|   Nina|  28|   nina@email.com| 55000|  2024-07-08|  Active|  Marketing|         6|   Tokyo|\n",
      "|102|   Name|NULL|unknown@email.com| 30000|  2024-07-08|  Status| Department|         1|Location|\n",
      "|102|    Bob|  25|unknown@email.com| 60000|  2023-07-20|  Active|    Finance|         5|  London|\n",
      "|104|Charlie|  28|charlie@email.com| 30000|  2021-05-10|Inactive|Engineering|         7|  Berlin|\n",
      "|106|   NULL|  30|unknown@email.com| 70000|  2024-09-18|  Active|      Sales|         4|   Tokyo|\n",
      "|109|   Gary|  27|unknown@email.com| 75000|  2020-02-29|  Active|         HR|         2|  Mumbai|\n",
      "|112|   Kate|  29|unknown@email.com| 48000|  2022-04-18|  Active|Engineering|         5|  London|\n",
      "|113|  Louis|  26|unknown@email.com| 70000|  2024-07-08|Inactive|         HR|         4|  Berlin|\n",
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "df_r = df_r.withColumn(\"Age\", when(col(\"Age\").isNull() | (col(\"Age\") == \"\"), 25).otherwise(col(\"Age\").cast(\"int\"))) \\\n",
    "           .withColumn(\"Status\", when(col(\"Status\").isNull() | (col(\"Status\") == \"\"), \"Active\").otherwise(col(\"Status\").cast(\"string\")))\n",
    "\n",
    "df_r.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f5776380-07e4-40fe-9d1b-233efd3ea0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r = df_r.na.fill({\"Age\": 25, \"Status\": \"Active\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "aee965c8-1d6d-4f0f-9d50-839a2d4ec466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "| ID|   Name| Age|            Email|Salary|Joining_Date|  Status| Department|Experience|LOCATION|\n",
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "|101|  Alice|  25|  alice@email.com| 50000|  2022-06-15|  Active|         HR|         3|New York|\n",
      "|103|  Alice|  25|  alice@email.com| 50000|  2022-06-15|  Active|         HR|         3|New York|\n",
      "|108|  Fiona|  26|  fiona@email.com| 55000|  2023-11-05|    NULL|    Finance|         6|  Sydney|\n",
      "|110|  Helen|NULL|  helen@email.com| 45000|  2018-06-07|Inactive|  Marketing|         8|   Dubai|\n",
      "|111|   John|  25|   john@email.com| 80000|  2021-11-10|  Active|         IT|         3|New York|\n",
      "|115|   Nina|  28|   nina@email.com| 55000|  2024-07-08|  Active|  Marketing|         6|   Tokyo|\n",
      "|102|   Name| Age|unknown@email.com| 30000|  2024-07-08|  Status| Department|         1|Location|\n",
      "|102|    Bob|  25|unknown@email.com| 60000|  2023-07-20|  Active|    Finance|         5|  London|\n",
      "|104|Charlie|  28|charlie@email.com| 30000|  2021-05-10|Inactive|Engineering|         7|  Berlin|\n",
      "|106|   NULL|  30|unknown@email.com| 70000|  2024-09-18|  Active|      Sales|         4|   Tokyo|\n",
      "|109|   Gary|  27|unknown@email.com| 75000|  2020-02-29|  Active|         HR|         2|  Mumbai|\n",
      "|112|   Kate|  29|unknown@email.com| 48000|  2022-04-18|  Active|Engineering|         5|  London|\n",
      "|113|  Louis|  26|unknown@email.com| 70000|  2024-07-08|Inactive|         HR|         4|  Berlin|\n",
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_r.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "92bdbd83-7bda-4d2f-a002-2495ea74fdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r = df_r.withColumn(\"Status\", when(col(\"Status\").isNull() | (trim(col(\"Status\")) == \" \") | (col(\"Status\") == \"None\"), \"Active\").otherwise(col(\"Status\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "98778a4b-4836-48f3-afd5-9515331c3626",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "| ID|   Name| Age|            Email|Salary|Joining_Date|  Status| Department|Experience|LOCATION|\n",
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "|101|  Alice|  25|  alice@email.com| 50000|  2022-06-15|  Active|         HR|         3|New York|\n",
      "|103|  Alice|  25|  alice@email.com| 50000|  2022-06-15|  Active|         HR|         3|New York|\n",
      "|108|  Fiona|  26|  fiona@email.com| 55000|  2023-11-05|    NULL|    Finance|         6|  Sydney|\n",
      "|110|  Helen|NULL|  helen@email.com| 45000|  2018-06-07|Inactive|  Marketing|         8|   Dubai|\n",
      "|111|   John|  25|   john@email.com| 80000|  2021-11-10|  Active|         IT|         3|New York|\n",
      "|115|   Nina|  28|   nina@email.com| 55000|  2024-07-08|  Active|  Marketing|         6|   Tokyo|\n",
      "|102|   Name| Age|unknown@email.com| 30000|  2024-07-08|  Status| Department|         1|Location|\n",
      "|102|    Bob|  25|unknown@email.com| 60000|  2023-07-20|  Active|    Finance|         5|  London|\n",
      "|104|Charlie|  28|charlie@email.com| 30000|  2021-05-10|Inactive|Engineering|         7|  Berlin|\n",
      "|106|   NULL|  30|unknown@email.com| 70000|  2024-09-18|  Active|      Sales|         4|   Tokyo|\n",
      "|109|   Gary|  27|unknown@email.com| 75000|  2020-02-29|  Active|         HR|         2|  Mumbai|\n",
      "|112|   Kate|  29|unknown@email.com| 48000|  2022-04-18|  Active|Engineering|         5|  London|\n",
      "|113|  Louis|  26|unknown@email.com| 70000|  2024-07-08|Inactive|         HR|         4|  Berlin|\n",
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_r.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b9a2218b-a057-4f88-b944-7fba7dfb4bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_data = df_r.select(\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "65b2f455-f769-4ef1-8827-c338c0674299",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "| ID|   Name| Age|            Email|Salary|Joining_Date|  Status| Department|Experience|LOCATION|\n",
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "|101|  Alice|  25|  alice@email.com| 50000|  2022-06-15|  Active|         HR|         3|New York|\n",
      "|103|  Alice|  25|  alice@email.com| 50000|  2022-06-15|  Active|         HR|         3|New York|\n",
      "|108|  Fiona|  26|  fiona@email.com| 55000|  2023-11-05|    NULL|    Finance|         6|  Sydney|\n",
      "|110|  Helen|NULL|  helen@email.com| 45000|  2018-06-07|Inactive|  Marketing|         8|   Dubai|\n",
      "|111|   John|  25|   john@email.com| 80000|  2021-11-10|  Active|         IT|         3|New York|\n",
      "|115|   Nina|  28|   nina@email.com| 55000|  2024-07-08|  Active|  Marketing|         6|   Tokyo|\n",
      "|102|   Name| Age|unknown@email.com| 30000|  2024-07-08|  Status| Department|         1|Location|\n",
      "|102|    Bob|  25|unknown@email.com| 60000|  2023-07-20|  Active|    Finance|         5|  London|\n",
      "|104|Charlie|  28|charlie@email.com| 30000|  2021-05-10|Inactive|Engineering|         7|  Berlin|\n",
      "|106|   NULL|  30|unknown@email.com| 70000|  2024-09-18|  Active|      Sales|         4|   Tokyo|\n",
      "|109|   Gary|  27|unknown@email.com| 75000|  2020-02-29|  Active|         HR|         2|  Mumbai|\n",
      "|112|   Kate|  29|unknown@email.com| 48000|  2022-04-18|  Active|Engineering|         5|  London|\n",
      "|113|  Louis|  26|unknown@email.com| 70000|  2024-07-08|Inactive|         HR|         4|  Berlin|\n",
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1cc8db23-abff-4ef7-8118-5758801d2d99",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: string (nullable = false)\n",
      " |-- Email: string (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      " |-- Joining_Date: string (nullable = true)\n",
      " |-- Status: string (nullable = false)\n",
      " |-- Department: string (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      " |-- LOCATION: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "180ce16c-c3d7-451a-b50e-b55f8f93f4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "CREATE TABLE Stage_temp_table(\n",
    "    ID INT,\n",
    "    Name STRING,\n",
    "    Age STRING,\n",
    "    Email STRING,\n",
    "    Salary INT,\n",
    "    Joining_Date STRING,\n",
    "    Status STRING,\n",
    "    Department STRING,\n",
    "    Experience INT,\n",
    "    LOCATION STRING\n",
    ")ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "STORED AS TEXTFILE\n",
    "LOCATION 'hdfs://localhost:9000/datasets/'\n",
    "\"\"\")\n",
    "\n",
    "df_final_data.write.mode(\"overwrite\").saveAsTable(\"Stage_temp_table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "39de22d7-140e-4072-938f-067f5254e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stg = spark.sql(\"SELECT * FROM Stage_temp_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5f16ba4a-1045-4cb6-b139-ea1825d27ebc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "| ID|   Name| Age|            Email|Salary|Joining_Date|  Status| Department|Experience|LOCATION|\n",
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "|101|  Alice|  25|  alice@email.com| 50000|  2022-06-15|  Active|         HR|         3|New York|\n",
      "|103|  Alice|  25|  alice@email.com| 50000|  2022-06-15|  Active|         HR|         3|New York|\n",
      "|108|  Fiona|  26|  fiona@email.com| 55000|  2023-11-05|    NULL|    Finance|         6|  Sydney|\n",
      "|110|  Helen|NULL|  helen@email.com| 45000|  2018-06-07|Inactive|  Marketing|         8|   Dubai|\n",
      "|111|   John|  25|   john@email.com| 80000|  2021-11-10|  Active|         IT|         3|New York|\n",
      "|115|   Nina|  28|   nina@email.com| 55000|  2024-07-08|  Active|  Marketing|         6|   Tokyo|\n",
      "|102|   Name| Age|unknown@email.com| 30000|  2024-07-08|  Status| Department|         1|Location|\n",
      "|102|    Bob|  25|unknown@email.com| 60000|  2023-07-20|  Active|    Finance|         5|  London|\n",
      "|104|Charlie|  28|charlie@email.com| 30000|  2021-05-10|Inactive|Engineering|         7|  Berlin|\n",
      "|106|   NULL|  30|unknown@email.com| 70000|  2024-09-18|  Active|      Sales|         4|   Tokyo|\n",
      "|109|   Gary|  27|unknown@email.com| 75000|  2020-02-29|  Active|         HR|         2|  Mumbai|\n",
      "|112|   Kate|  29|unknown@email.com| 48000|  2022-04-18|  Active|Engineering|         5|  London|\n",
      "|113|  Louis|  26|unknown@email.com| 70000|  2024-07-08|Inactive|         HR|         4|  Berlin|\n",
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a76792b5-2340-4c02-a89a-8527d72db161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with NULL values: 0\n",
      "+---+----+---+-----+------+------------+------+----------+----------+--------+\n",
      "| ID|Name|Age|Email|Salary|Joining_Date|Status|Department|Experience|LOCATION|\n",
      "+---+----+---+-----+------+------------+------+----------+----------+--------+\n",
      "+---+----+---+-----+------+------------+------+----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DQ_checks\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_null_check = stg.filter(\n",
    "    col(\"ID\").isNull() | \n",
    "    col(\"Name\").isNull() | \n",
    "    col(\"Age\").isNull() | \n",
    "    col(\"Email\").isNull() | \n",
    "    col(\"Salary\").isNull() | \n",
    "    col(\"Joining_Date\").isNull()\n",
    ")\n",
    "print(\"Rows with NULL values:\", df_null_check.count())\n",
    "df_null_check.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0c18503e-e2c7-4502-8f5e-c127aeb6a20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid Email Records: 0\n",
      "+---+----+---+-----+------+------------+------+----------+----------+--------+\n",
      "| ID|Name|Age|Email|Salary|Joining_Date|Status|Department|Experience|LOCATION|\n",
      "+---+----+---+-----+------+------------+------+----------+----------+--------+\n",
      "+---+----+---+-----+------+------------+------+----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_invalid_email = stg.filter(\n",
    "    ~col(\"Email\").rlike(\"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\\\.[a-zA-Z0-9-.]+$\")\n",
    ")\n",
    "\n",
    "print(\"Invalid Email Records:\", df_invalid_email.count())\n",
    "df_invalid_email.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3ef84bc0-cf27-48b1-ac96-58366849be43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid Salary Records: 0\n",
      "+---+----+---+-----+------+------------+------+----------+----------+--------+\n",
      "| ID|Name|Age|Email|Salary|Joining_Date|Status|Department|Experience|LOCATION|\n",
      "+---+----+---+-----+------+------------+------+----------+----------+--------+\n",
      "+---+----+---+-----+------+------------+------+----------+----------+--------+\n",
      "\n",
      "Invalid Age Records: 0\n",
      "+---+----+---+-----+------+------------+------+----------+----------+--------+\n",
      "| ID|Name|Age|Email|Salary|Joining_Date|Status|Department|Experience|LOCATION|\n",
      "+---+----+---+-----+------+------------+------+----------+----------+--------+\n",
      "+---+----+---+-----+------+------------+------+----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_invalid_salary = stg.filter((col(\"Salary\") <= 0))\n",
    "df_invalid_age = df_final_data.filter((col(\"Age\") < 18) | (col(\"Age\") > 100))\n",
    "\n",
    "print(\"Invalid Salary Records:\", df_invalid_salary.count())\n",
    "df_invalid_salary.show()\n",
    "\n",
    "print(\"Invalid Age Records:\", df_invalid_age.count())\n",
    "df_invalid_age.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "db5a7671-479b-41d6-a487-fbf46440625b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid Date Records: 0\n",
      "+---+----+---+-----+------+------------+------+----------+----------+--------+\n",
      "| ID|Name|Age|Email|Salary|Joining_Date|Status|Department|Experience|LOCATION|\n",
      "+---+----+---+-----+------+------------+------+----------+----------+--------+\n",
      "+---+----+---+-----+------+------------+------+----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "df_invalid_date = stg.filter(\n",
    "    to_date(col(\"Joining_Date\"), \"yyyy-MM-dd\").isNull()\n",
    ")\n",
    "\n",
    "print(\"Invalid Date Records:\", df_invalid_date.count())\n",
    "df_invalid_date.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "eedaec5b-220d-43b3-a396-db5da65d0ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_data = stg.dropDuplicates([\"ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c7e1e1bd-1120-4e73-88a2-c2d108212c49",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "| ID|   Name| Age|            Email|Salary|Joining_Date|  Status| Department|Experience|LOCATION|\n",
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "|101|  Alice|  25|  alice@email.com| 50000|  2022-06-15|  Active|         HR|         3|New York|\n",
      "|102|   Name| Age|unknown@email.com| 30000|  2024-07-08|  Status| Department|         1|Location|\n",
      "|103|  Alice|  25|  alice@email.com| 50000|  2022-06-15|  Active|         HR|         3|New York|\n",
      "|104|Charlie|  28|charlie@email.com| 30000|  2021-05-10|Inactive|Engineering|         7|  Berlin|\n",
      "|106|   NULL|  30|unknown@email.com| 70000|  2024-09-18|  Active|      Sales|         4|   Tokyo|\n",
      "|108|  Fiona|  26|  fiona@email.com| 55000|  2023-11-05|    NULL|    Finance|         6|  Sydney|\n",
      "|109|   Gary|  27|unknown@email.com| 75000|  2020-02-29|  Active|         HR|         2|  Mumbai|\n",
      "|110|  Helen|NULL|  helen@email.com| 45000|  2018-06-07|Inactive|  Marketing|         8|   Dubai|\n",
      "|111|   John|  25|   john@email.com| 80000|  2021-11-10|  Active|         IT|         3|New York|\n",
      "|112|   Kate|  29|unknown@email.com| 48000|  2022-04-18|  Active|Engineering|         5|  London|\n",
      "|113|  Louis|  26|unknown@email.com| 70000|  2024-07-08|Inactive|         HR|         4|  Berlin|\n",
      "|115|   Nina|  28|   nina@email.com| 55000|  2024-07-08|  Active|  Marketing|         6|   Tokyo|\n",
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "da4a7a1f-710e-4d15-b74e-2f0abe907c67",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid Status Records: 2\n",
      "+---+-----+---+-----------------+------+------------+------+----------+----------+--------+\n",
      "| ID| Name|Age|            Email|Salary|Joining_Date|Status|Department|Experience|LOCATION|\n",
      "+---+-----+---+-----------------+------+------------+------+----------+----------+--------+\n",
      "|108|Fiona| 26|  fiona@email.com| 55000|  2023-11-05|  NULL|   Finance|         6|  Sydney|\n",
      "|102| Name|Age|unknown@email.com| 30000|  2024-07-08|Status|Department|         1|Location|\n",
      "+---+-----+---+-----------------+------+------------+------+----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_invalid_status = stg.filter(~col(\"Status\").isin([\"Active\", \"Inactive\"]))\n",
    "print(\"Invalid Status Records:\", df_invalid_status.count())\n",
    "df_invalid_status.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "40d74d8e-aff9-48c0-b8fb-78b1413ef544",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "| ID|   Name| Age|            Email|Salary|Joining_Date|  Status| Department|Experience|LOCATION|\n",
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "|101|  Alice|  25|  alice@email.com| 50000|  2022-06-15|  Active|         HR|         3|New York|\n",
      "|103|  Alice|  25|  alice@email.com| 50000|  2022-06-15|  Active|         HR|         3|New York|\n",
      "|108|  Fiona|  26|  fiona@email.com| 55000|  2023-11-05|  Active|    Finance|         6|  Sydney|\n",
      "|110|  Helen|NULL|  helen@email.com| 45000|  2018-06-07|Inactive|  Marketing|         8|   Dubai|\n",
      "|111|   John|  25|   john@email.com| 80000|  2021-11-10|  Active|         IT|         3|New York|\n",
      "|115|   Nina|  28|   nina@email.com| 55000|  2024-07-08|  Active|  Marketing|         6|   Tokyo|\n",
      "|102|   Name| Age|unknown@email.com| 30000|  2024-07-08|  Active| Department|         1|Location|\n",
      "|102|    Bob|  25|unknown@email.com| 60000|  2023-07-20|  Active|    Finance|         5|  London|\n",
      "|104|Charlie|  28|charlie@email.com| 30000|  2021-05-10|Inactive|Engineering|         7|  Berlin|\n",
      "|106|   NULL|  30|unknown@email.com| 70000|  2024-09-18|  Active|      Sales|         4|   Tokyo|\n",
      "|109|   Gary|  27|unknown@email.com| 75000|  2020-02-29|  Active|         HR|         2|  Mumbai|\n",
      "|112|   Kate|  29|unknown@email.com| 48000|  2022-04-18|  Active|Engineering|         5|  London|\n",
      "|113|  Louis|  26|unknown@email.com| 70000|  2024-07-08|Inactive|         HR|         4|  Berlin|\n",
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, col, trim\n",
    "\n",
    "df_cleaned = stg.withColumn(\"Status\", \n",
    "    when(col(\"Status\").isNull() | (trim(col(\"Status\")) == \"\") | (~col(\"Status\").isin(\"Active\", \"Inactive\")), \"Active\")\n",
    "    .otherwise(col(\"Status\"))\n",
    ")\n",
    "\n",
    "df_cleaned.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d5c74e19-6038-4d9a-9e82-9e03676063d3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid Status Records: 0\n",
      "+---+----+---+-----+------+------------+------+----------+----------+--------+\n",
      "| ID|Name|Age|Email|Salary|Joining_Date|Status|Department|Experience|LOCATION|\n",
      "+---+----+---+-----+------+------------+------+----------+----------+--------+\n",
      "+---+----+---+-----+------+------------+------+----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_invalid_status = df_cleaned.filter(~col(\"Status\").isin([\"Active\", \"Inactive\"]))\n",
    "print(\"Invalid Status Records:\", df_invalid_status.count())\n",
    "df_invalid_status.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "034e8c40-a790-428c-aa51-e864d56cb65e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Email: string (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      " |-- Joining_Date: string (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      " |-- LOCATION: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cleaned.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cb9fcf08-4f65-4c7f-95ae-6cc22b304600",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "CREATE TABLE Final_table(\n",
    "    ID INT,\n",
    "    Name STRING,\n",
    "    Age STRING,\n",
    "    Email STRING,\n",
    "    Salary INT,\n",
    "    Joining_Date STRING,\n",
    "    Status STRING,\n",
    "    Department STRING,\n",
    "    Experience INT,\n",
    "    LOCATION STRING\n",
    ")ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "STORED AS TEXTFILE\n",
    "LOCATION 'hdfs://localhost:9000/datasets/'\n",
    "\"\"\")\n",
    "\n",
    "df_cleaned.write.mode(\"overwrite\").saveAsTable(\"Final_table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fdfe4d35-b6df-45f0-b399-6c63cd9e47e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_table_data = spark.sql(\"SELECT * FROM Final_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "43506bd6-0d9a-46e6-9546-762b8ed0d3af",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "| ID|   Name| Age|            Email|Salary|Joining_Date|  Status| Department|Experience|LOCATION|\n",
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "|101|  Alice|  25|  alice@email.com| 50000|  2022-06-15|  Active|         HR|         3|New York|\n",
      "|103|  Alice|  25|  alice@email.com| 50000|  2022-06-15|  Active|         HR|         3|New York|\n",
      "|108|  Fiona|  26|  fiona@email.com| 55000|  2023-11-05|  Active|    Finance|         6|  Sydney|\n",
      "|110|  Helen|NULL|  helen@email.com| 45000|  2018-06-07|Inactive|  Marketing|         8|   Dubai|\n",
      "|111|   John|  25|   john@email.com| 80000|  2021-11-10|  Active|         IT|         3|New York|\n",
      "|115|   Nina|  28|   nina@email.com| 55000|  2024-07-08|  Active|  Marketing|         6|   Tokyo|\n",
      "|102|   Name| Age|unknown@email.com| 30000|  2024-07-08|  Active| Department|         1|Location|\n",
      "|102|    Bob|  25|unknown@email.com| 60000|  2023-07-20|  Active|    Finance|         5|  London|\n",
      "|104|Charlie|  28|charlie@email.com| 30000|  2021-05-10|Inactive|Engineering|         7|  Berlin|\n",
      "|106|   NULL|  30|unknown@email.com| 70000|  2024-09-18|  Active|      Sales|         4|   Tokyo|\n",
      "|109|   Gary|  27|unknown@email.com| 75000|  2020-02-29|  Active|         HR|         2|  Mumbai|\n",
      "|112|   Kate|  29|unknown@email.com| 48000|  2022-04-18|  Active|Engineering|         5|  London|\n",
      "|113|  Louis|  26|unknown@email.com| 70000|  2024-07-08|Inactive|         HR|         4|  Berlin|\n",
      "+---+-------+----+-----------------+------+------------+--------+-----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Final_table_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7b41a959-7542-4a56-bc4e-0c1b342544f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b914f5ce-6650-4f65-87a9-9381afa2bb76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
